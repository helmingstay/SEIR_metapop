#' Compute per capita weekly incidence 
#'
#' Compute per capita weekly incidence from xts matrix of case reports 
#' and data.frame of reporting and population sizes.
#' Includes optional handling of zeros.
#' @return A rescaled copy of \code{.cases}
mk.incid <- function(.reprates, .cases, add=0, weeks=1, zero.denom=2) {
    ## treat zeros as?
    .cases[.cases==0] <- 1/zero.denom
    ## log1p or not?
    .ret <- .cases + add
    ## for each place, get 
    for (.place in colnames(.ret) ) {
        .dat <- subset(.reprates, placename==.place)
        .ret[,.place] <- with(.dat, 
            ## get weekly per capita incidence from case reports
            .ret[,.place] / (pop*reprate*weeks)
        )
    }
    .ret
}


#' Compute empirical cumulative distribution function (ECDF)
#'
#' Compute per-column ECDF of log incidence. Optionally omit zeros and NAs.
#' @param myxts Matrix xts of per capita incidence (generated by
#' \code{mk.incid}
#' @return A data.frame with containing the ECDF of log(percap) for each
#' location / input-column 
mk.ecdf <- function(myxts, na.rm=T, zero.rm=T) {
    ## first, melt percap timeseries
    ret <- melt(as.data.frame(myxts), value.name='percap', variable.name='placename')
    if( na.rm) {
        ret <- na.omit(ret)
    }
    ret <- ddply( ret, 'placename', function(x) {
        if (zero.rm) {
            x <- x[!x$percap==0,]
        }
        x$logcap <- log10(x$percap)
        x$prop <- ecdf(x$percap)(x$percap)
        x
    })
}
    
#' Measure distance between distribution and data
#'
#' Used by optim to fit a normal distribution to 
#' ECDF of log incidence.  Default uses normal distribution 
#' and KS (Linf norm).
#' @return The numeric distance 
mk.fitdist = function(params, x, y, norm=function(y) max(y), distrib=pnorm, par1.min=-10, par2.min=0.05) {
    ## optimization function 
    ## compute distance between the distribution defined by x + params
    ## assumed to be mean and sd of pnorm and y
    ## e.g. compute pnorm(log10(prev), params) -  prop
    ## pass only 1 factor-combination of the data frame in at a time!!
    ## metric:
    ## norm = sum : L1 
    ## norm = max : Linf 
    ## norm default : euclidean
    ## nn = measure dimension
    ##
    ## give some guidance to parameters...
    ## don't let sd or mean go to low
    if (params[1] < par1.min | params[2] < par2.min)  return(Inf)
    ## get residuals
    myresid = as.vector( distrib(x, params[1], params[2]) - (y))
    ## return RSS  (or whatever norm)
    ret = norm(abs(myresid))
    return(ret)
}


#' Infer distribution of log incidence
#' Should remove sample statistics!!
#'
#' Use optim to fit a normal distribution to 
#' ECDF of log incidence.  Default uses normal distribution 
#' and KS (Linf norm).
#' @return A data.frame with (log-space) mean, sd, and error for each location
mk.dist <- function(mydf, norm=function(x) max(x)) {
    ## take (previously modified w/zeros, add) dataframe
    ## of ECDF of percap incidence
    ## return sample mean/sd, inferred mean/sd, 
    ## and ks distance between modified ecdf & estimated dist
    ## ??any way to get distance from unmodified dist?
    ret <- ddply(mydf, 'placename', function(x) { 
        ## use sample mean and sd for initial conditions
        est.init <- c(mean(x$logcap), sd(x$logcap))
        ## also return them
        ret.sample <- data.frame(which='sample',
            var=c('mean', 'sd'),
            val=est.init
        )
        ## repeat to prevent local minima 
        est.new <- optim( est.init, mk.fitdist, 
            x=x$logcap, y=x$prop, norm=norm
        )$par
        ## update initial conditions from estimate
        est.fin <- optim( est.new, mk.fitdist, 
            x=x$logcap, y=x$prop, norm=norm
        )$par
        ## final inferred estimates
        ret.infer <- data.frame(which='infer',
            var=c('mean', 'sd'),
            val=est.fin
        )
        ## join sample and inferred
        ret.fin <- rbind(ret.infer, ret.sample)
        ## compute ks distance for inferred/sample
        ret.fin <- ddply(ret.fin, 'which', function(.df) {
            ## pull out first row, modify to insert error
            .tmp.ret <- .df[1,]
            .tmp.ret$var <- 'error'
            ## pull out mean/sd
            .mean <- subset(.df, var=='mean')$val
            .sd <- subset(.df, var=='sd')$val
            ## find dist between data and dist
            .tmp.ret$val <- max(abs(
                x$prop - pnorm(x$logcap, .mean, .sd)
            ))
            ## return mean, sd, error together
            rbind(.df,.tmp.ret)
        })
        ret.fin
    })
    ret
}

#' Wrapper function - ecdf, distribution
#' Infer distribution of case reports 
#' (which can then be scaled by reprate)
mk.alldist <- function(.cases, 
    .zero.as=1, .na.as=NA, norm=max
) {
    ## set zeros to 1
    .cases[.cases==0] <- .zero.as
    ## can we assume NAs represent few cases??
    .cases[is.na(.cases)] <- .na.as
    ## get ECFD of case reports
    ## zero.rm=T, only affects (.add=0 && .denom=Inf)
    .ecdf <- mk.ecdf(.cases)
    ## Infer distribution from ECDF
    .dist <- mk.dist(.ecdf, norm=norm)
    ## we don't need sample mean/sd
    .dist <- droplevels(subset(.dist, which=='infer'))
    .dist <- dcast( .dist, ... ~ var, value.var='val')
    .dist
}
 
